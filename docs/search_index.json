[["index.html", "Paper Notes Preface", " Paper Notes Nicholas Lyu 2024-05-26 Preface "],["preliminaries.html", "1 Preliminaries 1.1 Notation 1.2 Fermionic operators 1.3 Clifford-Grassmann Fourier transform 1.4 Grassmann integrals 1.5 Classical simulatibility", " 1 Preliminaries 1.1 Notation Definition 1.1 (vector and matrix notation) We sometimes denote a vector \\(\\mathbf v\\) with components \\(v_j\\) by \\((v_j)\\) or, when it is clear from context, simply \\(v\\). Similarly, paranthesis around matrix components \\((h_{jk})\\) denote the matrix \\(\\mathbf h\\). Definition 1.2 (multi-index notation) We often work with multi-indices, which are ordered subsets of an index set \\([N]=\\{1, \\cdots, N\\}\\). The index set should be clear from context. Single indices are denoted by lower-case \\(a, b, c, d, j, k, l, \\cdots\\), while upper-case \\(I, J, K, \\cdots\\) denote multi-indices. For example, when \\(J=\\{1, 2, 4\\}\\), the expression (here \\(a_j\\) is often an operator) \\[ a_J = a_1a_2a_4 \\] Given a defined-multi-index \\(J\\), we use \\(|J|\\), or sometimes simply \\(j\\), to denote its order. For our example, \\(|J|=j=3\\). Definition 1.3 (summation notation) A free index which appears twice in an expression is summed over. Single-indices sum over the index set, while multi-indices sum over the power-set of the index set. 1.2 Fermionic operators Definition 1.4 (creation and annihilation operators) The annihilation operators \\(a_j^\\dagger\\) and creation operators \\(a_j\\) satisfy the canonical anti-commutation relations \\[ \\{a_i, a_j^\\dagger\\} = \\delta_{ij}, \\quad \\{a_i, a_j\\} = 0 \\] We use \\(\\mathbf a\\), or sometimes just \\(a\\) (when clear from context), to denote the vector of \\(2n\\) operators \\[ \\mathbf a = (a_1, a_1^\\dagger, a_2, a_2^\\dagger, \\cdots) \\] Definition 1.5 (majorana operators) The \\(2n\\) majorana operators over \\(n\\) fermionic modes is given by \\[ \\begin{pmatrix} q_j \\\\ p_j \\end{pmatrix} = \\Omega \\begin{pmatrix} a_j \\\\ a_j^\\dagger \\end{pmatrix} = \\dfrac 1 {\\sqrt{2}}\\begin{pmatrix} a_j + a_j^\\dagger\\\\ (a_j^\\dagger- a_j)i \\end{pmatrix}, \\quad \\Omega = \\dfrac 1 {\\sqrt 2} \\begin{pmatrix} 1 &amp; 1 \\\\ -i &amp; i \\end{pmatrix} \\] We use \\(\\gamma\\) to denote the vector of \\(2n\\) majorana operators \\[ (\\gamma_j) = (q_1, p_1, \\cdots, q_n, p_n), \\quad \\{\\gamma_j, \\gamma_k\\} = \\delta_{jk} \\] The \\(2n\\) majorana operators freely generate a \\(2^{2n}\\)-dimensional Clifford algebra we denote \\(\\mathcal C_{2n}\\). The basis for \\(\\mathcal C_{2n}\\) are the \\(2^{2n}\\) monomials \\(\\gamma_J\\) which are at most linear in the generators \\(\\gamma_j\\). Definition 1.6 (Jordan-Wigner transform, ONB) Depending on context, it is often more convenient to define \\(\\gamma_j\\mapsto \\sqrt 2\\gamma_j\\) so \\(q_j=a_j+a_j^\\dagger, p_j=(a_j^\\dagger-a_j)i\\). In this case the majorana operators may be represented by the Pauli operators \\[ q_j = Z^{\\otimes (j-1)}\\otimes X \\otimes I^{\\otimes (n-j)}, \\quad p_j = Z^{\\otimes (j-1)}\\otimes Y \\otimes I^{\\otimes (n-j)} \\] One may check that this faithfully represents the Clifford algebra \\(\\{\\gamma_j, \\gamma_k\\} = 2\\delta_{jk}\\) in \\(\\mathbb C^{2n}\\), the Hilbert space over \\(n\\) qubits. Moreover, the generated basis \\((\\gamma_J)\\) is orthonormal under the Hilbert-Schmidt inner product \\[ \\langle A, B\\rangle= \\dfrac 1 {2^n} \\mathrm{tr}(A^\\dagger B) \\] Thus, given a \\(n\\)-qubit operator \\(X\\in \\mathcal C_{2n}\\), we have the decomposition (note the implicit summation) \\[ X = X_J \\gamma_J, \\quad X_J = \\langle\\gamma_J, X\\rangle= \\dfrac 1 {2^n} \\mathrm{tr}(\\gamma_J^\\dagger B) \\] Note that \\(\\gamma_J^\\dagger= (-1)^{j(j-1)/2}\\gamma_J\\) since it requires \\(j(j-1)/2\\) swaps to reorder \\(J\\) from reversed order. Definition 1.7 (Grassmann numbers) There are also \\(2n\\) Grassmann numbers associated with \\(n\\) fermionic modes often labeled by \\(\\theta, \\omega, \\eta, \\cdots\\). They freely generate the \\(2^{2n}\\)-dimensional Grassmann algebra \\(\\mathcal G_{2n}\\). Grassmann numbers are always taken to anti-commute with other operators, including both Grassmann and majorana operators. 1.3 Clifford-Grassmann Fourier transform There is a suitable definition of Fourier transform between the Grassmann and Clifford algebras. To the best of our knowledge, this notion of the Fourier transform first appeared in (Hudson, Wilkinson, and Peck 1980). Definition 1.8 (Fourier transform) Given \\(X=X_J\\gamma_J\\), its fourier transform is the Grassmann element \\(X(\\theta)\\in \\mathcal G_{2n}\\) defined by \\[ X(\\theta) = X_J \\theta_J \\] Given the JW-transform, this takes on the more inspiring form \\[ X(\\theta) = \\dfrac 1 {2^n} \\mathrm{tr}_{\\mathcal C_{2n}}(e^{\\gamma_j\\theta_j} X) \\] When \\(X\\) is a density operator, \\(X(\\theta)\\) is its moment-generating function. The classical analogue is the moment-generating function \\[ M_X(t) = \\mathbb E[e^{tX}] = \\int e^{tx} f_X(x)\\, dx \\] Formal substitution is equivalent to the tracial formula by means of the following convenient identity. Proposition 1.1 Given Grassmann generators \\(\\theta\\) and majorana generators \\(\\gamma\\) which anti-commute with each other \\[ \\exp(\\gamma_j\\theta_j) = (-1)^{j(j-1)/2} \\theta_J \\gamma_J = \\theta_J \\gamma_J^\\dagger \\] Similarly, for Grassmann generators \\(\\theta, \\eta\\) \\[ \\exp(\\theta_j\\eta_j) = (-1)^{j(j-1)/2)}\\theta_J \\eta_J \\] Proof: without loss of generality consider \\(J=[k]\\) for some \\(k\\leq 2n\\). The \\(k\\)-th degree of the expansion contains \\(\\theta_1\\gamma_1\\cdots\\theta_k\\gamma_k\\). There are \\(k!\\) of such terms, cancelling the \\(1/k!\\) taylor coefficient, and ordering this into \\(\\theta_J\\eta_J\\) requires \\(j(j-1)/2\\) swaps. Theorem 1.1 (Fourier formula for inner product) Given \\(X, Y\\in \\mathcal C_{2n}\\), the trace \\(\\mathrm{tr}(X, Y)\\) may be computed in Fourier-space as a Grassmann integral \\[ \\dfrac 1 {2^n}\\mathrm{tr}(XY) = (-1)^n \\int D\\theta\\, D\\eta \\, e^{\\theta^T\\eta} X(\\theta) Y(\\eta) \\] Let \\(X=X_J \\gamma_J\\) and similarly for \\(Y\\), then \\[ \\dfrac 1 {2^n}\\mathrm{tr}(XY) = \\dfrac 1 {2^n}\\mathrm{tr}(X_JY_K \\gamma_J\\gamma_K) = X_J Y_J \\dfrac 1 {2^n}\\mathrm{tr}(\\gamma_J^2) = (-1)^{j(j-1)/2} X_JY_J \\] On the RHS, the integrand expands to \\((-1)^{l(l-1)/2}X_J Y_K \\theta_L\\eta_L\\theta_J\\eta_K\\). The highest-order in \\(\\theta, \\eta\\) arises from \\(J=K, L=[2n]-J=\\bar J\\), then substituting \\(l=2n-j\\) yields \\[ \\int D\\theta\\, D\\eta \\, e^{\\theta^T\\eta} X(\\theta) Y(\\eta) = (-1)^{(2n-j)((2n-j)-1)/2}X_J Y_J\\int D\\theta\\, D\\eta\\, \\theta_{\\bar J}\\eta_{\\bar J} \\theta_J \\eta_J \\] Reordering to match the signs \\[ \\theta_{\\bar J}\\eta_{\\bar J}\\theta_J \\eta_J = (-1)^{j(2n-j)}\\theta_{\\bar J}\\theta_J \\eta_{\\bar J}\\eta_J = (-1)^{j(2n-j)}\\eta_{\\bar J}\\eta_J\\theta_{\\bar J}\\theta_J = (-1)^{j(2n-j)}\\eta_{[2n]}\\theta_{[2n]} \\] Recollecting the parity in the \\((-2)^n\\) factor, the parities of the LHS and RHS are respectively \\[ \\dfrac 1 2 j(j-1) \\equiv n + j(2n-j) + \\dfrac 1 2 (2n-j)(2n-j-1) \\mod 2 \\] 1.4 Grassmann integrals The following two formulas are found in (Knill 2001). We expand upon the proofs. Theorem 1.2 (homogeneous Gaussian integral) For \\(2n\\times 2n\\) antisymmetric \\(M\\) \\[ \\int D\\theta \\exp\\left(\\dfrac i 2 \\theta^T M \\theta\\right) = i^n \\mathrm{Pf}(M) \\] Proof: Using antisymmetry to cancel the factor of \\(2\\) and summing over \\(j&lt;k\\) \\[ \\exp\\left(\\dfrac i 2 \\theta^T M \\theta\\right) = \\exp\\left(i M_{jk}\\theta_j \\theta_k \\right) \\] Here \\(D\\theta\\) extracts the maximal-degree element in the sum, then \\[ \\int D\\theta \\, \\exp\\left(\\dfrac i 2 \\theta^T M \\theta\\right) = \\exp\\left(i M_{jk}\\theta_j \\theta_k \\right) = \\int D\\theta \\, \\dfrac{i^n}{n!} \\left(M_{jk}\\theta_j \\theta_k\\right)^n = i^n \\sum_{p\\in \\mathcal P_n} \\sigma_p \\prod_{b\\in p} M_{b_1}M_{b_2} \\] where \\(\\mathcal P_n\\) is the set of pair-partitions of \\(2n\\), the factor \\(1/n!\\) is canceled by the \\(n!\\) number of ways we can pick across the \\(n\\) identical products \\((M_{jk}\\theta_j\\theta_k)\\). Theorem 1.3 (affine Gaussian integral) Given anti-symmetric \\(M\\) and \\(\\eta, \\theta\\in \\mathcal G_{4n}\\) mutually anticommuting \\[ \\int D\\theta \\, \\exp \\left(\\eta^T\\theta + \\dfrac i 2 \\theta^T M \\theta\\right) = i^n \\mathrm{Pf}(M)\\exp\\left(-\\dfrac i 2 \\eta^T M^{-1}\\eta\\right) \\] Proof: Complete the square: find \\(\\xi, N\\) such that (here \\(j, k\\) are totally summed-over) \\[ \\eta^T \\theta + \\dfrac i 2 \\theta^T M \\theta = \\dfrac i 2 (\\theta + \\xi)^T M (\\theta + \\xi) + \\dfrac 1 2 \\eta^T N \\eta = \\dfrac i 2 M_{jk} (\\theta_j + \\xi_j)(\\theta_k + \\xi_k) + \\dfrac 1 2 N_{jk}\\eta_j\\eta_k \\] Matching the linear term yields \\(\\xi = i M^{-1}\\eta, \\xi_j = i M^{-1}_{jk}\\eta_k\\) \\[ \\eta^T \\theta = \\eta_j \\theta_j = \\dfrac i 2 \\left(M_{jk} \\theta_j \\xi_k + M_{jk} \\xi_j \\theta_k\\right) = i (M_{jk} \\theta_j \\xi_k) \\implies \\eta_j = i M_{jk}\\xi_k \\] Matching the quadratic term in \\(\\eta\\) yields \\(N=-iM^{-1}\\) \\[\\begin{aligned} -\\dfrac 1 2 N_{jk}\\eta_j \\eta_k &amp;= \\dfrac i 2 \\xi_j M_{jk} \\xi_k = \\dfrac i 2 (i M_{ja}^{-1}\\eta_a) M_{jk} (i M_{kb}^{-1}\\eta_b) = -\\dfrac i 2 M_{ja}^{-1}\\eta_a \\delta_{jb} \\eta_b = \\dfrac i 2 \\eta_a M_{ab}^{-1}\\eta_b \\end{aligned}\\] Using commutativity to bring \\(\\exp(\\eta^TN\\eta/2)\\) out of the integral and the shift-invariant property \\[\\begin{aligned} \\int D\\theta \\, \\exp \\left(\\eta^T\\theta + \\dfrac i 2 \\theta^T M \\theta\\right) &amp;= \\int D\\theta \\, \\exp \\left(\\dfrac i 2 (\\theta + \\xi)^T M (\\theta + \\xi) + \\dfrac 1 2 \\eta^T N \\eta\\right)\\\\ &amp;= \\exp\\left(\\dfrac 1 2 \\eta^T N\\eta\\right) \\int D\\theta\\,\\left(\\dfrac i 2 (\\theta + \\xi)^T M (\\theta + \\xi) \\right)\\\\ &amp;= i^n \\mathrm{Pf}(M) \\exp\\left(-\\dfrac i 2 \\eta^T M^{-1}\\eta\\right) \\end{aligned}\\] Theorem 1.4 (Gaussian operator overlap) Given Gaussian operators \\(X, Y\\) and \\(X\\) Hermitian \\[ X(\\eta) = \\exp\\left(\\dfrac i 2 \\eta^T A\\eta\\right), \\quad Y(\\theta) = \\exp\\left(\\dfrac i 2 \\theta^T B\\theta\\right) \\] Using theorems 1.3 and 1.1 yields \\[ \\langle X, Y\\rangle= (-i)^n \\mathrm{Pf}(A)\\mathrm{Pf}(B - A^{-1}) \\] Proof: Using Hermiticity \\(X^\\dagger= X\\) \\[\\begin{aligned} \\langle X, Y\\rangle &amp;= \\dfrac 1 {2^n}\\mathrm{tr}(XY) = (-1)^n \\int D\\theta\\, D\\eta \\, e^{\\theta^T\\eta} X(\\eta) Y(\\theta) \\\\ &amp;= (-1)^n \\int D\\theta \\exp\\left(\\dfrac i 2 \\theta^T B\\theta\\right) \\int D\\eta \\, e^{\\theta^T\\eta} \\exp\\left(\\dfrac i 2 \\eta^T A\\eta\\right) \\\\ &amp;= (-1)^n \\int D\\theta \\exp\\left(\\dfrac i 2 \\theta^T B\\theta\\right) i^n \\mathrm{Pf}(A) \\exp\\left(-\\dfrac i 2 \\theta^T A^{-1} \\theta\\right) \\\\ &amp;= (-i)^n \\mathrm{Pf}(A)\\mathrm{Pf}(B - A^{-1}) \\end{aligned}\\] 1.5 Classical simulatibility The following notions of classical simulatibility are taken from (Brod 2016). For the following two definitions, we consider a uniformly family of quantum circuits \\(\\{C_n\\}\\). Definition 1.9 (Strong simulation) \\(\\{C_n\\}\\) is strongly simulable if, for every \\(k\\) and assignment of \\(k\\) output bits \\(\\tilde y\\), one can compute \\(\\Pr(\\tilde y|\\psi_n)\\) in \\(\\mathrm{poly}(n)\\) time on a classical computer. Definition 1.10 (weak simulation) \\(\\{C_n\\}\\) is weakly simulable if sampling from \\(\\Pr(\\tilde y|\\psi_n)\\) can be done in \\(\\mathrm{poly}(n)\\) time on a classical computer. Now consider a uniform family of adaptive quantum circuits \\(\\{C_n\\}\\) where one is allowed to make intermediate measurements and condition subsequent operations on their outcomes. Definition 1.11 (weak simulation) \\(\\{C_n\\}\\) is adaptively simulable if All intermediate measurements are weakly simulable. The final measurements on the circuit, conditioning on intermediate outcomes, is strongly simulable. Bibliography Brod, Daniel J. 2016. “Efficient Classical Simulation of Matchgate Circuits with Generalized Inputs and Measurements.” Physical Review A 93 (6): 062332. Hudson, RL, MD Wilkinson, and SN Peck. 1980. “Translation-Invariant Integrals, and Fourier Analysis on Clifford and Grassmann Algebras.” Journal of Functional Analysis 37 (1): 68–87. Knill, Emanuel. 2001. “Fermionic Linear Optics and Matchgates.” arXiv Preprint Quant-Ph/0108033. "],["computational-basis-gaussian-circuits.html", "2 Computational-basis Gaussian Circuits 2.1 Insightful general case 2.2 Generalization", " 2 Computational-basis Gaussian Circuits This work (Terhal and DiVincenzo 2002) is the first to draw the connection between Valiant’s matchgates and noninteracting fermions. It proves that Gaussian circuits with computational basis input and computational-basis von-Neumann measurements are both strongly and adaptively simulable. 2.1 Insightful general case Let us first consider a subclass of number-preserving Gaussian unitaries and projective measurements in the computational basis. This case suffices to show the main insight of the paper. Definition 2.1 (number-preserving unitary) A Gaussian unitary \\(U\\) is number-preserving if it does not mix annihilation and creation operators. The following operator \\((V_{jk})\\) is unitary \\[ U a_j^\\dagger U^\\dagger= V_{jk} a_k^\\dagger\\implies U^\\dagger a_j^\\dagger U = V^\\dagger_{jk} a_k^\\dagger, \\quad U^\\dagger a_j U = (V_{jk}^\\dagger)^* a_k = V_{kj} a_k \\] Note that \\(U\\) preserves the hamming weights of computational basis states. In particular, \\(U|0\\rangle= |0\\rangle\\). Proposition 2.1 (computational basis measurement) Let \\(|I\\rangle, |K\\rangle\\) be computational basis states. One can efficiently compute \\(\\langle K|U|I\\rangle\\) by the following procedure. Consider \\[\\begin{aligned} U|I\\rangle &amp;= U a^\\dagger_I |0\\rangle= U a_I^\\dagger U^\\dagger(U|0\\rangle) = \\sum_{j_1\\cdots j_i} V_{I_1j_1}\\cdots V_{I_iJ_i} a_{j_1}^\\dagger\\cdots a_{j_i}^\\dagger|0\\rangle \\end{aligned}\\] When paired with \\(\\langle K|\\), only when \\((j_l)\\) is a permutation of \\(K\\) will this be nonzero, then \\[ \\langle K|U|I\\rangle= \\sum_{J\\in \\pi(K)} \\mathrm{sgn}(J) V_{IJ} = \\det V_{|IK} \\] Here \\(\\pi(K)\\) denotes permutations of \\(K\\) and \\(V_{|IK}\\) is the \\(i\\times i\\) matrix which selects the \\(I\\) rows and \\(K\\) columns of \\(V\\). 2.2 Generalization Theorem 2.1 (strong simulation) Given a Gaussian unitary \\(U\\) acting on a computational basis \\(|J\\rangle\\), the probability \\(\\Pr(K^*|J)\\), where \\(K^*\\) of measuring any subset \\(K\\subset [2n]\\) of the qubits and finding the bitstring \\(K^*\\in \\{0, 1\\}^k\\), is efficiently classically computable. The proof extends that of the special case 2.1. One generalizes computational-basis projective to von-Neumann measurement by applying Wick’s theorem and recognizing the sum as a Pfaffian of a cleverly-constructed matrix (instead of the determinant). The generalization from number-preserving to parity-preserving Gaussian unitaries is done by using the majorana instead of the dirac operators. Constructing the matrix whose Pfaffian yield the desired quantity is quite technical. A much more insightful interpretation is that this problem reduces to computing the overlap between \\(U|J\\rangle\\) and the binary Hermitian observable corresponding to \\(K^*\\). Both are Gaussian, so the Gaussian overlap formula 1.4 applies. The next result follows. Theorem 2.2 (adaptive simulation) Adaptive Gaussian circuits with computational-basis input and computational-basis von-Neumann measurements are adaptively simulable. Bibliography Terhal, Barbara M, and David P DiVincenzo. 2002. “Classical Simulation of Noninteracting-Fermion Quantum Circuits.” Physical Review A 65 (3): 032325. "],["bounded-output-gaussian-circuits.html", "3 Bounded-output Gaussian circuits", " 3 Bounded-output Gaussian circuits This work (Jozsa and Miyake 2008) provides strong simulation for Gaussian circuits with arbitrary product-state input and measurements with bounded majorana support. Bibliography Jozsa, Richard, and Akimasa Miyake. 2008. “Matchgates and Classical Simulation of Quantum Circuits.” Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences 464 (2100): 3089–3106. "],["general-product-gaussian-circuits.html", "4 General product Gaussian circuits 4.1 Product input and measurement simulation", " 4 General product Gaussian circuits This work (Brod 2016) shows that Gaussian circuits with arbitrary product states input and arbitrary product-state intermediate measurements remain classically simulable. 4.1 Product input and measurement simulation Theorem 4.1 (product-input multiple-output simulation) Let \\(\\{M_n\\}\\) be a uniform family of (possibly adaptive) quantum circuits with \\(\\mathrm{poly}(n)\\) Gaussian unitaries over \\(n\\) qubits acting on an arbitrary \\(n\\)-qubit product state \\(|\\psi\\rangle= \\otimes |\\psi_n\\rangle\\). The circuit is strongly and adaptively simulable. Bibliography Brod, Daniel J. 2016. “Efficient Classical Simulation of Matchgate Circuits with Generalized Inputs and Measurements.” Physical Review A 93 (6): 062332. "],["magic-states.html", "5 Magic states", " 5 Magic states Hello "],["bibliography.html", "Bibliography", " Bibliography Brod, Daniel J. 2016. “Efficient Classical Simulation of Matchgate Circuits with Generalized Inputs and Measurements.” Physical Review A 93 (6): 062332. Hudson, RL, MD Wilkinson, and SN Peck. 1980. “Translation-Invariant Integrals, and Fourier Analysis on Clifford and Grassmann Algebras.” Journal of Functional Analysis 37 (1): 68–87. Jozsa, Richard, and Akimasa Miyake. 2008. “Matchgates and Classical Simulation of Quantum Circuits.” Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences 464 (2100): 3089–3106. Knill, Emanuel. 2001. “Fermionic Linear Optics and Matchgates.” arXiv Preprint Quant-Ph/0108033. Terhal, Barbara M, and David P DiVincenzo. 2002. “Classical Simulation of Noninteracting-Fermion Quantum Circuits.” Physical Review A 65 (3): 032325. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]

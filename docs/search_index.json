[["index.html", "Fermionic Gaussian Computation Preface", " Fermionic Gaussian Computation Nicholas Lyu 2024-05-28 Preface This set of notes document existing and ongoing research efforts for fermionic Gaussian computation, also known as fermionic linear optics in physics and matchgate computation in computer science. It is a rich area of research lying at the intersection of physics, computer science, and statistics. "],["preliminaries.html", "1 Preliminaries 1.1 Notation 1.2 Fermionic operators 1.3 Clifford-Grassmann Fourier transform 1.4 Grassmann calculus 1.5 Classical simulatibility", " 1 Preliminaries 1.1 Notation Definition 1.1 (vector and matrix notation) We sometimes denote a vector \\(\\mathbf v\\) with components \\(v_j\\) by \\((v_j)\\) or, when it is clear from context, simply \\(v\\). Similarly, paranthesis around matrix components \\((h_{jk})\\) denote the matrix \\(\\mathbf h\\). Definition 1.2 (multi-index notation) We often work with multi-indices, which are ordered subsets of an index set \\([N]=\\{1, \\cdots, N\\}\\). The index set should be clear from context. Single indices are denoted by lower-case \\(a, b, c, d, j, k, l, \\cdots\\), while upper-case \\(I, J, K, \\cdots\\) denote multi-indices. For example, when \\(J=\\{1, 2, 4\\}\\), the expression (here \\(a_j\\) is often an operator) \\[ a_J = a_1a_2a_4 \\] Given a defined-multi-index \\(J\\), we use \\(|J|\\), or sometimes simply \\(j\\), to denote its order. For our example, \\(|J|=j=3\\). Definition 1.3 (summation notation) A free index which appears twice in an expression is summed over. Single-indices sum over the index set, while multi-indices sum over the power-set of the index set. 1.2 Fermionic operators Definition 1.4 (creation and annihilation operators) The annihilation operators \\(a_j^\\dagger\\) and creation operators \\(a_j\\) satisfy the canonical anti-commutation relations \\[ \\{a_i, a_j^\\dagger\\} = \\delta_{ij}, \\quad \\{a_i, a_j\\} = 0 \\] We use \\(\\mathbf a\\), or sometimes just \\(a\\) (when clear from context), to denote the vector of \\(2n\\) operators \\[ \\mathbf a = (a_1, a_1^\\dagger, a_2, a_2^\\dagger, \\cdots) \\] Definition 1.5 (majorana operators) The \\(2n\\) majorana operators over \\(n\\) fermionic modes is given by \\[ \\begin{pmatrix} q_j \\\\ p_j \\end{pmatrix} = \\Omega \\begin{pmatrix} a_j \\\\ a_j^\\dagger \\end{pmatrix} = \\begin{pmatrix} a_j + a_j^\\dagger\\\\ (a_j^\\dagger- a_j)i \\end{pmatrix}, \\quad \\Omega = \\begin{pmatrix} 1 &amp; 1 \\\\ -i &amp; i \\end{pmatrix} \\] We use \\(\\gamma\\) to denote the vector of \\(2n\\) majorana operators \\[ (\\gamma_j) = (q_1, p_1, \\cdots, q_n, p_n), \\quad \\{\\gamma_j, \\gamma_k\\} = 2\\delta_{jk} \\] The \\(2n\\) majorana operators freely generate a \\(2^{2n}\\)-dimensional Clifford algebra we denote \\(\\mathcal C_{2n}\\) (note the factor of \\(2\\)). The basis for \\(\\mathcal C_{2n}\\) are the \\(2^{2n}\\) monomials \\(\\gamma_J\\) which are at most linear in the generators \\(\\gamma_j\\). Definition 1.6 (Jordan-Wigner transform, ONB) The majorana operators may be represented by the Pauli operators \\[ q_j = Z^{\\otimes (j-1)}\\otimes X \\otimes I^{\\otimes (n-j)}, \\quad p_j = Z^{\\otimes (j-1)}\\otimes Y \\otimes I^{\\otimes (n-j)} \\] One may check that this faithfully represents the Clifford algebra in \\(\\mathbb C^{2n}\\), the Hilbert space over \\(n\\) qubits. Moreover, the generated basis \\((\\gamma_J)\\) is orthonormal under the Hilbert-Schmidt inner product \\[ \\langle A, B\\rangle= \\dfrac 1 {2^n} \\mathrm{tr}(A^\\dagger B) \\] Thus, given a \\(n\\)-qubit operator \\(X\\in \\mathcal C_{2n}\\), we have the decomposition (note the implicit summation) \\[ X = X_J \\gamma_J, \\quad X_J = \\langle\\gamma_J, X\\rangle= \\dfrac 1 {2^n} \\mathrm{tr}(\\gamma_J^\\dagger B) \\] Note that \\(\\gamma_J^\\dagger= (-1)^{j(j-1)/2}\\gamma_J\\) since it requires \\(j(j-1)/2\\) swaps to reorder \\(J\\) from reversed order. Definition 1.7 (Grassmann numbers) There are also \\(2n\\) Grassmann numbers associated with \\(n\\) fermionic modes often labeled by \\(\\theta, \\omega, \\eta, \\cdots\\). They freely generate the \\(2^{2n}\\)-dimensional Grassmann algebra \\(\\mathcal G_{2n}\\). Grassmann numbers are always taken to anti-commute with other operators, including both Grassmann and majorana operators. 1.3 Clifford-Grassmann Fourier transform There is a suitable definition of Fourier transform between the Grassmann and Clifford algebras. To the best of our knowledge, this notion of the Fourier transform first appeared in (Hudson, Wilkinson, and Peck 1980). Definition 1.8 (Fourier transform) Given \\(X=X_J\\gamma_J\\), its fourier transform is the Grassmann element \\(X(\\theta)\\in \\mathcal G_{2n}\\) defined by \\[ X(\\theta) = X_J \\theta_J \\] Given the JW-transform, this takes on the more inspiring form \\[ X(\\theta) = \\dfrac 1 {2^n} \\mathrm{tr}_{\\mathcal C_{2n}}(e^{\\gamma_j\\theta_j} X) \\] When \\(X\\) is a density operator, \\(X(\\theta)\\) is its moment-generating function. The classical analogue is the moment-generating function \\[ M_X(t) = \\mathbb E[e^{tX}] = \\int e^{tx} f_X(x)\\, dx \\] Formal substitution is equivalent to the tracial formula by means of the following convenient identity. Proposition 1.1 Given Grassmann generators \\(\\theta\\) and majorana generators \\(\\gamma\\) which anti-commute with each other \\[ \\exp(\\gamma_j\\theta_j) = (-1)^{j(j-1)/2} \\theta_J \\gamma_J = \\theta_J \\gamma_J^\\dagger \\] Similarly, for Grassmann generators \\(\\theta, \\eta\\) \\[ \\exp(\\theta_j\\eta_j) = (-1)^{j(j-1)/2)}\\theta_J \\eta_J \\] Proof: without loss of generality consider \\(J=[k]\\) for some \\(k\\leq 2n\\). The \\(k\\)-th degree of the expansion contains \\(\\theta_1\\gamma_1\\cdots\\theta_k\\gamma_k\\). There are \\(k!\\) of such terms, cancelling the \\(1/k!\\) taylor coefficient, and ordering this into \\(\\theta_J\\eta_J\\) requires \\(j(j-1)/2\\) swaps. Theorem 1.1 (Fourier formula for inner product) Given \\(X, Y\\in \\mathcal C_{2n}\\), the trace \\(\\mathrm{tr}(X, Y)\\) may be computed in Fourier-space as a Grassmann integral \\[ \\dfrac 1 {2^n}\\mathrm{tr}(XY) = (-1)^n \\int D\\theta\\, D\\eta \\, e^{\\theta^T\\eta} X(\\theta) Y(\\eta) \\] Let \\(X=X_J \\gamma_J\\) and similarly for \\(Y\\), then \\[ \\dfrac 1 {2^n}\\mathrm{tr}(XY) = \\dfrac 1 {2^n}\\mathrm{tr}(X_JY_K \\gamma_J\\gamma_K) = X_J Y_J \\dfrac 1 {2^n}\\mathrm{tr}(\\gamma_J^2) = (-1)^{j(j-1)/2} X_JY_J \\] On the RHS, the integrand expands to \\((-1)^{l(l-1)/2}X_J Y_K \\theta_L\\eta_L\\theta_J\\eta_K\\). The highest-order in \\(\\theta, \\eta\\) arises from \\(J=K, L=[2n]-J=\\bar J\\), then substituting \\(l=2n-j\\) yields \\[ \\int D\\theta\\, D\\eta \\, e^{\\theta^T\\eta} X(\\theta) Y(\\eta) = (-1)^{(2n-j)((2n-j)-1)/2}X_J Y_J\\int D\\theta\\, D\\eta\\, \\theta_{\\bar J}\\eta_{\\bar J} \\theta_J \\eta_J \\] Reordering to match the signs \\[ \\theta_{\\bar J}\\eta_{\\bar J}\\theta_J \\eta_J = (-1)^{j(2n-j)}\\theta_{\\bar J}\\theta_J \\eta_{\\bar J}\\eta_J = (-1)^{j(2n-j)}\\eta_{\\bar J}\\eta_J\\theta_{\\bar J}\\theta_J = (-1)^{j(2n-j)}\\eta_{[2n]}\\theta_{[2n]} \\] Recollecting the parity in the \\((-2)^n\\) factor, the parities of the LHS and RHS are respectively \\[ \\dfrac 1 2 j(j-1) \\equiv n + j(2n-j) + \\dfrac 1 2 (2n-j)(2n-j-1) \\mod 2 \\] 1.4 Grassmann calculus Definition 1.9 (Grassmann differentiation and integration) A partial derivative \\(\\partial_{a}\\) over Grassmann numbers \\((\\theta_j)\\) generating \\(\\mathcal G_{2n}\\) is the linear operator \\(\\partial_{a}:\\mathcal G_{2n}\\to \\mathcal G_{2n}\\) defined by \\[ \\partial_{a} 1 = 0, \\quad \\partial_{a} \\theta_b = \\delta_{ab}, \\quad \\partial_{a} [\\theta_b f(\\theta)] = \\delta_{ab}f(\\theta) - \\theta_b\\partial_{a} f(\\theta) \\] It follows that Grassmann derives anti-commute \\[ \\partial_{ab}^2 + \\partial_{ba}^2 = 0 \\] Grassmann integration is the same as differentiation: \\(\\int d\\theta_a = \\partial_{a}\\), with the notation \\[ \\int D\\theta = \\int d\\theta_n\\cdots d\\theta_1\\implies \\int D\\theta\\, \\theta_{[2n]} = 1 \\] Proposition 1.2 (Leibniz rule) when \\(f(\\theta)\\) has homogeneous degree \\(\\sigma \\in \\{-1, 1\\}\\), we have \\[ \\partial_{a} [f(\\theta)g(\\theta)] = [\\partial_{a} f(\\theta)]g(\\theta) + \\sigma f(\\theta) \\partial_{b} g(\\theta) \\] Proposition 1.3 (integration by part) If one of \\(f, g\\) is even, then \\[ \\int D\\theta\\, (\\partial_{a} f)g = \\pm \\int D\\theta\\, f\\partial_{a} g \\] with \\(+, -\\) standing for even \\(g\\) or even \\(f\\), respectively. Proof: Now \\(\\partial_{a} (fg) = (\\partial_{a} f)g + \\sigma_f \\partial_{a} g\\). Apply \\(\\int D\\theta\\) to both sides, rearrange, and note that \\(\\int D\\theta \\, \\partial_{a}(\\cdots) = 0\\) yields \\[ \\int D\\theta\\, (\\partial_{a} f)g = -\\sigma_f \\int D\\theta\\, \\partial_{a} g + \\int D\\theta\\, (\\partial_{a} f)g \\] 1.4.1 Grassmann fourier identities Definition 1.10 (dirac delta function) The Grassmann analogue of the dirac delta function is \\[\\begin{aligned} \\delta(\\theta, \\mu) &amp;= \\prod_a (\\theta_a - \\mu_a) = \\int D\\eta \\, \\exp\\left[(\\theta - \\mu)^T\\eta \\right] \\\\ X(\\theta) &amp;= \\int D\\mu\\, \\delta(\\theta, \\mu) X(\\mu) \\end{aligned}\\] To see the first equation, the \\(2n\\)-degree expansion of \\(\\exp\\) is \\[\\begin{aligned} \\prod i(\\theta_j - \\mu_j)\\eta_j &amp;= i^{2n} (-1)^{2n(2n-1)/2} \\mu_{[2n]} \\prod \\theta_j - \\mu_j = \\mu_{[2n]} \\prod\\theta_j - \\mu_j \\end{aligned}\\] To see the second property, \\(\\delta(\\theta, \\mu) = \\sigma_{J, \\bar J}(-1)^j \\theta_{J} \\mu_{\\bar J}\\), where \\(\\sigma_{J, \\bar J}\\) is the sign associated with rearranging \\([2n]\\to (J, \\bar J)\\). Note that the sign associated with rearranging \\((\\bar J, J)\\to [2n]\\) is then exactly \\(\\sigma_{J, \\bar J}(-1)^j\\), then \\[ \\int D\\mu\\, \\delta(\\theta, \\mu) \\mu_K = \\int D\\mu\\, \\sigma_{J, \\bar J}(-1)^j \\theta_{J} \\mu_{\\bar J} \\mu_K = \\theta_K \\] 1.4.2 Gaussian integrals The following two formulas are found in (Bravyi 2004). We expand upon the proofs. Theorem 1.2 (homogeneous Gaussian integral) For \\(2n\\times 2n\\) antisymmetric \\(M\\) \\[ \\int D\\theta \\exp\\left(\\dfrac i 2 \\theta^T M \\theta\\right) = i^n \\mathrm{Pf}(M) \\] Proof: Using antisymmetry to cancel the factor of \\(2\\) and summing over \\(j&lt;k\\) \\[ \\exp\\left(\\dfrac i 2 \\theta^T M \\theta\\right) = \\exp\\left(i M_{jk}\\theta_j \\theta_k \\right) \\] Here \\(D\\theta\\) extracts the maximal-degree element in the sum, then \\[ \\int D\\theta \\, \\exp\\left(\\dfrac i 2 \\theta^T M \\theta\\right) = \\exp\\left(i M_{jk}\\theta_j \\theta_k \\right) = \\int D\\theta \\, \\dfrac{i^n}{n!} \\left(M_{jk}\\theta_j \\theta_k\\right)^n = i^n \\sum_{p\\in \\mathcal P_n} \\sigma_p \\prod_{b\\in p} M_{b_1}M_{b_2} \\] where \\(\\mathcal P_n\\) is the set of pair-partitions of \\(2n\\), the factor \\(1/n!\\) is canceled by the \\(n!\\) number of ways we can pick across the \\(n\\) identical products \\((M_{jk}\\theta_j\\theta_k)\\). Theorem 1.3 (affine Gaussian integral) Given anti-symmetric \\(M\\) and \\(\\eta, \\theta\\in \\mathcal G_{4n}\\) mutually anticommuting \\[ \\int D\\theta \\, \\exp \\left(\\eta^T\\theta + \\dfrac i 2 \\theta^T M \\theta\\right) = i^n \\mathrm{Pf}(M)\\exp\\left(-\\dfrac i 2 \\eta^T M^{-1}\\eta\\right) \\] Proof: Complete the square: find \\(\\xi, N\\) such that (here \\(j, k\\) are totally summed-over) \\[ \\eta^T \\theta + \\dfrac i 2 \\theta^T M \\theta = \\dfrac i 2 (\\theta + \\xi)^T M (\\theta + \\xi) + \\dfrac 1 2 \\eta^T N \\eta = \\dfrac i 2 M_{jk} (\\theta_j + \\xi_j)(\\theta_k + \\xi_k) + \\dfrac 1 2 N_{jk}\\eta_j\\eta_k \\] Matching the linear term yields \\(\\xi = i M^{-1}\\eta, \\xi_j = i M^{-1}_{jk}\\eta_k\\) \\[ \\eta^T \\theta = \\eta_j \\theta_j = \\dfrac i 2 \\left(M_{jk} \\theta_j \\xi_k + M_{jk} \\xi_j \\theta_k\\right) = i (M_{jk} \\theta_j \\xi_k) \\implies \\eta_j = i M_{jk}\\xi_k \\] Matching the quadratic term in \\(\\eta\\) yields \\(N=-iM^{-1}\\) \\[\\begin{aligned} -\\dfrac 1 2 N_{jk}\\eta_j \\eta_k &amp;= \\dfrac i 2 \\xi_j M_{jk} \\xi_k = \\dfrac i 2 (i M_{ja}^{-1}\\eta_a) M_{jk} (i M_{kb}^{-1}\\eta_b) = -\\dfrac i 2 M_{ja}^{-1}\\eta_a \\delta_{jb} \\eta_b = \\dfrac i 2 \\eta_a M_{ab}^{-1}\\eta_b \\end{aligned}\\] Using commutativity to bring \\(\\exp(\\eta^TN\\eta/2)\\) out of the integral and the shift-invariant property \\[\\begin{aligned} \\int D\\theta \\, \\exp \\left(\\eta^T\\theta + \\dfrac i 2 \\theta^T M \\theta\\right) &amp;= \\int D\\theta \\, \\exp \\left(\\dfrac i 2 (\\theta + \\xi)^T M (\\theta + \\xi) + \\dfrac 1 2 \\eta^T N \\eta\\right)\\\\ &amp;= \\exp\\left(\\dfrac 1 2 \\eta^T N\\eta\\right) \\int D\\theta\\,\\left(\\dfrac i 2 (\\theta + \\xi)^T M (\\theta + \\xi) \\right)\\\\ &amp;= i^n \\mathrm{Pf}(M) \\exp\\left(-\\dfrac i 2 \\eta^T M^{-1}\\eta\\right) \\end{aligned}\\] Theorem 1.4 (Gaussian operator overlap) Given Gaussian operators \\(X, Y\\) and \\(X\\) Hermitian \\[ X(\\eta) = \\exp\\left(\\dfrac i 2 \\eta^T A\\eta\\right), \\quad Y(\\theta) = \\exp\\left(\\dfrac i 2 \\theta^T B\\theta\\right) \\] Using theorems 1.3 and 1.1 yields \\[ \\langle X, Y\\rangle= (-i)^n \\mathrm{Pf}(A)\\mathrm{Pf}(B - A^{-1}) \\] Proof: Using Hermiticity \\(X^\\dagger= X\\) \\[\\begin{aligned} \\langle X, Y\\rangle &amp;= \\dfrac 1 {2^n}\\mathrm{tr}(XY) = (-1)^n \\int D\\theta\\, D\\eta \\, e^{\\theta^T\\eta} X(\\eta) Y(\\theta) \\\\ &amp;= (-1)^n \\int D\\theta \\exp\\left(\\dfrac i 2 \\theta^T B\\theta\\right) \\int D\\eta \\, e^{\\theta^T\\eta} \\exp\\left(\\dfrac i 2 \\eta^T A\\eta\\right) \\\\ &amp;= (-1)^n \\int D\\theta \\exp\\left(\\dfrac i 2 \\theta^T B\\theta\\right) i^n \\mathrm{Pf}(A) \\exp\\left(-\\dfrac i 2 \\theta^T A^{-1} \\theta\\right) \\\\ &amp;= (-i)^n \\mathrm{Pf}(A)\\mathrm{Pf}(B - A^{-1}) \\end{aligned}\\] 1.5 Classical simulatibility The following notions of classical simulatibility are taken from (Brod 2016). For the following two definitions, we consider a uniformly family of quantum circuits \\(\\{C_n\\}\\). Definition 1.11 (Strong simulation) \\(\\{C_n\\}\\) is strongly simulable if, for every \\(k\\) and assignment of \\(k\\) output bits \\(\\tilde y\\), one can compute \\(\\Pr(\\tilde y|\\psi_n)\\) in \\(\\mathrm{poly}(n)\\) time on a classical computer. Definition 1.12 (weak simulation) \\(\\{C_n\\}\\) is weakly simulable if sampling from \\(\\Pr(\\tilde y|\\psi_n)\\) can be done in \\(\\mathrm{poly}(n)\\) time on a classical computer. Now consider a uniform family of adaptive quantum circuits \\(\\{C_n\\}\\) where one is allowed to make intermediate measurements and condition subsequent operations on their outcomes. Definition 1.13 (weak simulation) \\(\\{C_n\\}\\) is adaptively simulable if All intermediate measurements are weakly simulable. The final measurements on the circuit, conditioning on intermediate outcomes, is strongly simulable. Bibliography Bravyi, Sergey. 2004. “Lagrangian Representation for Fermionic Linear Optics.” arXiv Preprint Quant-Ph/0404180. Brod, Daniel J. 2016. “Efficient Classical Simulation of Matchgate Circuits with Generalized Inputs and Measurements.” Physical Review A 93 (6): 062332. Hudson, RL, MD Wilkinson, and SN Peck. 1980. “Translation-Invariant Integrals, and Fourier Analysis on Clifford and Grassmann Algebras.” Journal of Functional Analysis 37 (1): 68–87. "],["gaussian-operators.html", "2 Gaussian Operators 2.1 Even Gaussian 2.2 Lie algebra embedding 2.3 Affine Gaussian", " 2 Gaussian Operators The following definition Gaussian operators in terms of their Fourier property is made by (Bravyi 2005). Definition 2.1 (Gaussian operator) An operator \\(A\\in \\mathcal C_{2n}\\) with \\(\\mathrm{tr}(A)\\neq 0\\) is affine Gaussian if \\[ X(\\theta) = C\\exp\\left(\\dfrac 1 2 \\theta^T M\\theta + d^T\\theta\\right) \\] for some antisymmetric \\((M_{jk})\\in \\mathbb C^{2n\\times 2n}\\) and \\(d\\in \\mathbb C^{2n}\\). It is (even) Gaussian if \\(d\\) vanishes, which is equivalent to \\(X(\\theta)\\) being homogeneously even. Traceless Gaussians are defined as limits. The correlation matrix of \\(X(\\theta)\\) as above is in fact \\(-iM\\). Two special cases Affine Gaussian hermitian operator: in this case the correlation matrix is just \\(h\\) \\[ H(\\theta) = C\\exp\\left(\\dfrac i 2 \\theta^T h\\theta + d^T\\theta\\right), \\quad (h_{jk})\\in \\mathfrak{so}(2n, \\mathbb R), \\quad (d_j)\\in \\mathbb R^{2n} \\] Affine Gaussian unitary: \\[ U(\\theta) = C\\exp\\left(\\dfrac 1 2 \\theta^T u\\theta + id^T\\theta\\right), \\quad (u_{jk})\\in \\mathfrak{so}(2n, \\mathbb R), \\quad (d_j)\\in \\mathbb R^{2n} \\] Unlike in traditional statistics, fermionic Gaussians with zero mean is the norm rather than exception for most existing research. This is partly due to the boson-fermion superselection rule. We focus on even Gaussians first then extend known results, as possible, to affine Gaussians. 2.1 Even Gaussian Characterization Theorem 2.1 (effect of Gaussian unitaries) Consider a Gaussian unitary \\[ U = \\exp\\left(\\dfrac 1 2 \\gamma^T h \\gamma\\right), \\quad h_{jk}=-h_{kj}\\in \\mathbb R \\] Then it affects rotation of the majorana operators \\[ U \\gamma_j U^\\dagger= R_{jk}\\gamma_k, \\quad R = e^{2h} \\] Proof: Using standard Lie theory technique, define \\(\\gamma_j=\\theta(0)\\) and \\[ \\theta(t) = U(t) \\theta(0) U(t)^\\dagger = \\tilde \\gamma_j(t)\\gamma_j, \\quad U(t) = \\exp\\left(\\dfrac t 2 \\gamma^T h \\gamma \\right) \\] Differentiation yields \\[ \\partial_{t} \\theta(t) = \\left[\\dfrac 1 2 \\gamma^T h \\gamma, \\theta(t) \\right] \\] The key here is the commutator bracket. Using \\([\\gamma_a\\gamma_b, \\gamma_a]=-2\\gamma_b\\) we obtain \\[\\begin{align} \\partial_{t} \\theta(t) &amp;= \\dfrac 1 2 \\sum_{a, b, j} \\tilde \\gamma_j(t)h_{ab}[\\gamma_a\\gamma_b, \\gamma_j] = \\dfrac 1 2 \\sum_{b, j} \\tilde \\gamma_j(t)h_{jb}[\\gamma_j\\gamma_b, \\gamma_j] + \\dfrac 1 2 \\sum_{a, j} \\tilde \\gamma_j(t)h_{aj}[\\gamma_a\\gamma_j, \\gamma_j] \\\\ &amp;= \\sum_{j, b} -2 h_{jb} \\tilde \\gamma_j(t) \\gamma_b = \\sum_b \\partial_{t} \\tilde \\gamma_b(t)\\gamma_b \\\\ \\partial_{t} \\tilde \\gamma_b(t) &amp;= -2 h_{jb} \\gamma_j(t) = 2h_{bj}\\gamma_j(t) \\end{align}\\] The solution to this differential equation is \\[ \\tilde \\gamma(t) = R(t)\\tilde \\gamma(0), \\quad R(t) = e^{2h} \\in SO(2n) \\] It follows that \\((UXU^\\dagger)(\\theta) = X(R\\theta)\\). Theorem 2.2 (characterization of Gaussian states) The following three characterizations of Gaussian states \\(\\rho\\) are equivalent. \\(\\rho(\\theta) = 2^{-n} \\exp(i \\theta^T M \\theta/2)\\). \\(\\rho(\\theta) = U(|0\\rangle\\langle 0|)^{\\otimes n}U^\\dagger\\), for some Gaussian unitary \\(U\\). \\(\\rho = e^{H}/\\mathrm{tr}(e^H)\\) for some \\(H\\) which is homogeneously quadratic in majorana operators. Pure states are defined in the limit \\(H\\mapsto \\lim_{t\\to \\infty} tH\\). Fourier perspective Bravyi’s work (Bravyi 2004) provides many important results about Gaussian operators and maps from the Fourier perspective. Theorem 2.3 (fourier characterization of Gaussian operators) An operator \\(X\\in \\mathcal C_{2n}\\) is Gaussian iff it is even and satisfies \\[ [\\hat \\Lambda, X\\otimes X]=0, \\quad \\hat \\Lambda = \\gamma_a\\otimes \\gamma_a \\] Proof: We first derive the adjoint action of \\(\\hat \\Lambda\\) in fourier space 2.1. The two directions 2.2, 2.3 follow. Lemma 2.1 Consider the following differential operator \\(\\Delta_a:\\mathcal G_{2n}\\otimes \\mathcal G_{2n}\\to \\mathcal G_{2n}\\otimes \\mathcal G_{2n}\\). \\[ \\Delta_a = 2(\\theta_a\\otimes \\partial_{a} + \\partial_{a} \\otimes \\theta_a) \\] For any \\(Y, Z\\in \\mathcal C_{2n}\\) having the same parity \\[ [\\gamma_a\\otimes \\gamma_a, Y\\otimes Z](\\theta) = \\Delta_a[Y(\\theta)\\otimes Z(\\theta)] \\] Proof: Take \\(Y, Z\\) to be monomials \\(\\gamma_J, \\gamma_K\\). If neither \\(J, K\\) contains \\(a\\) then both sides vanish. If both \\(J, K\\) contains \\(a\\), then the LHS vanishes by commutation, and both terms of the RHS are annihilated by \\(\\theta_a\\). If only \\(J\\) contains \\(a\\), then \\(\\gamma_a\\otimes \\gamma_a\\) anticommutes with \\(\\gamma_J\\otimes \\gamma_K\\) since \\(J\\) contains one less factor than \\(K\\) for \\(\\gamma_a\\) to commute across, then \\[ [\\gamma_a\\otimes \\gamma_a, \\gamma_J\\otimes \\gamma_K] = 2 \\gamma_a \\gamma_J \\otimes \\gamma_a \\gamma_K \\] On the right hand side, only the second term in \\(\\Delta_a\\) survives, with \\[ 2 (\\partial_{a} \\otimes \\theta_a) \\theta_J \\otimes \\theta_K \\] The two coefficients are seen to be equal: commuting \\(\\partial_{a}\\) (resp. \\(\\gamma_a\\)) across \\(\\gamma_J\\) (resp. \\(\\theta_J\\)) takes the same number of swaps. Lemma 2.2 Given a Gaussian operator \\(X(\\theta)=\\exp(i\\theta^TM\\theta/2)\\) \\[ \\sum_a \\Delta_a[X(\\theta)\\otimes X(\\theta)]=0\\implies [\\Lambda, X\\otimes X] = 0 \\] The traceless case follows by continuity. Proof: First compute \\(\\partial_{a} X = i M_{ab}\\theta_b X\\). This is not at all apparant as it seems, the exponential property arises from the power rule \\(\\partial_{x} x^n = nx^{n-1}\\), which is only true in Grassmann calculus if \\(x\\) (in this case \\(iM_{ab}\\theta^TM\\theta/2\\)) is even. Then \\[\\begin{equation}\\begin{aligned} \\left[\\hat \\Lambda, X\\otimes X\\right](\\theta) &amp;= 2\\sum_a \\left(\\theta_a \\otimes \\partial_{a} + \\partial_{a} \\otimes \\theta_a \\right) \\exp\\left(\\dfrac i 2 \\theta^T M \\theta\\right)^{\\otimes 2} \\\\ &amp;= 2\\sum_{a, b} \\theta_a X \\otimes iM_{ab} \\theta_b X + iM_{ab} \\theta_b X \\otimes \\theta_a X \\\\ &amp;= 2 i \\sum_{a, b} M_{ab} (\\theta_a \\otimes \\theta_b) (X\\otimes X) = 0 \\end{aligned}\\end{equation}\\] Lemma 2.3 Suppose \\(X\\in \\mathcal C_{2n}\\) is even with \\(\\sum \\Delta_a [X(\\theta)\\otimes X(\\theta)]=0\\), then \\(X\\) is Gaussian. Proof: We provide the proof for non-vanishing trace case. Pin down the degree expansion of \\(X(\\theta)\\) \\[ X(\\theta) = C + \\dfrac{iC}{2} M_{ab}\\theta_a\\theta_b + O(\\theta^4) \\iff X(\\theta) = C \\exp\\left(\\dfrac{i}{2} M_{ab}\\theta_a\\theta_b + \\cdots\\right) \\] Apply \\(1\\otimes \\partial_{b}\\) to the equation of interest, yielding \\[\\begin{aligned} 0 &amp;= (1\\otimes \\partial_{b}) \\sum_a (\\theta_a X \\otimes \\partial_{a} X + \\partial_{a} X\\otimes \\theta_a X) \\\\ &amp;= \\sum_a \\theta_aX \\otimes \\partial_{ba}^2 X + \\partial_{a} X \\otimes (\\delta_{ab}X - \\theta_a \\partial_{b} X) \\\\ &amp;= \\partial_{b} X \\otimes X + \\sum_a \\theta_aX \\otimes \\partial_{ba}^2 X - \\partial_{a} X \\otimes \\theta_a \\partial_{b} X \\\\ \\end{aligned}\\] Consider the weaker equation where we only look at the linear term in the second tensor component, then the last term above vanishes due to \\(\\theta_a\\) and the equation simplifies to \\[\\begin{aligned} 0 &amp;= \\partial_{b} X \\otimes C + \\sum_a \\theta_aX \\otimes \\dfrac{iC}{2}M_{ab} \\implies 0 = \\partial_{b} X + \\dfrac i 2 \\sum_a M_{ab} \\theta_a X \\end{aligned}\\] This suffices to show that \\(X\\) must be Gaussian. Gaussian linear maps Definition 2.2 (Gaussian linear map) A linear map \\(\\mathcal E:\\mathcal C_{2n}\\to \\mathcal C_{2n}\\) is Gaussian if \\[ \\mathcal E(X)(\\theta) = C\\int D\\eta\\, D\\mu\\, \\exp \\left[S(\\theta, \\eta) + i \\eta^T \\mu\\right] X(\\mu), \\quad S(\\theta, \\eta) = \\dfrac i 2 \\begin{pmatrix} \\theta \\\\ \\eta \\end{pmatrix} ^T \\begin{pmatrix} A &amp; B \\\\ -B^T &amp; D \\end{pmatrix} \\begin{pmatrix} \\theta \\\\ \\eta \\end{pmatrix} \\tag{2.1} \\] Here \\(A, D\\) are antisymmetric and \\(B\\) arbitrary. All values are complex. It’s also insightful to expand the whole expression using \\(\\theta^TB\\eta - \\eta^TB^T\\theta = 2\\theta^T B \\eta\\) \\[ \\mathcal E(X)(\\theta) = C\\exp\\left(\\dfrac i 2 \\theta^TA\\theta\\right)\\int D\\eta\\, \\exp \\left[(iB^T \\theta)^T \\eta + \\dfrac i 2 \\eta^T D \\eta \\right] \\int D\\mu\\, \\exp(i \\eta^T \\mu) X(\\mu) \\tag{2.2} \\] Example 2.1 (identity map) Recalling the Grassmann dirac delta 1.10. \\[ X(\\theta) = \\int D\\eta\\, D\\mu\\, \\exp(i\\theta^T\\eta + i\\eta^T\\mu) X(\\mu) \\implies S = \\begin{pmatrix} 0 &amp; I \\\\ -I &amp; 0 \\end{pmatrix} \\] Proposition 2.1 Gaussian linear maps are parity-preserving. Proof: Consider the automorphism \\(\\overline{(\\cdot)}\\) such that \\(\\overline X(\\theta) = X(-\\theta)\\). It suffices to prove that \\[ \\overline{\\mathcal E(X)} = \\mathcal E(\\overline X) \\] Here \\(\\overline{\\mathcal E(X)}(\\theta)\\) is equivalent to replacing \\(\\theta\\mapsto -\\theta\\) in (2.1), while \\(\\mathcal E(\\overline X)(\\theta)\\) is equivalent to replacing \\(\\mu\\mapsto -\\mu\\). They yield the same expression upon substitution by virtue of \\(S(\\theta, -\\eta) = S(-\\theta, \\eta)\\) and \\(D(-\\mu) = D\\mu, D(-\\eta) = D\\eta\\). Proposition 2.2 Gaussian linear maps map Gaussian operators into Gausian operators. Proof: Since \\(\\mathcal E\\) is parity preserving, it suffices to apply 2.3 on \\(\\mathcal E(X)\\), for \\(X\\) Gaussian. Note the following identity \\[\\begin{equation} \\sum_a (\\theta_a\\otimes \\partial_{\\theta_a} + \\partial_{\\theta_a}\\otimes \\theta_a) (e^{i\\theta^TB\\eta})^{\\otimes 2} = -\\sum_a (\\eta_a\\otimes \\partial_{\\eta_a} + \\partial_{\\eta_a}\\otimes \\eta_a) (e^{i\\theta^TB\\eta})^{\\otimes 2} \\tag{2.3} \\end{equation}\\] We also need the Leibniz rule 1.2 and integration by part formula 1.3. Rewrite (2.1) using an auxillary polynomial \\(f(\\eta)\\) \\[ \\mathcal E(X)(\\theta) = C\\int D\\eta\\, \\exp \\left[S(\\theta, \\eta)\\right] f(\\eta), \\quad f(\\eta) = \\int D\\mu\\, e^{i\\eta^T\\mu} X(\\mu) \\] One can show that \\(f(\\eta)\\) is even. One can go on to show that \\[ \\Lambda_{\\mathrm{ad}} \\, \\mathcal E(X)\\otimes \\mathcal E(X) = \\mathcal E\\otimes \\mathcal E(\\Lambda_{\\mathrm{ad}}\\, X\\otimes X) = 0 \\] Theorem 2.4 (effect of Gaussian linear maps) Let \\(X\\) be a Gaussian operator with correlation \\(M\\) and pre-exponential factor \\(C\\), then \\(\\mathcal E(X)\\) as defined in (2.1) has correlation matrix \\[\\begin{equation} \\mathcal E(M) = B(M^{-1}+D)^{-1}B^T + A \\tag{2.4} \\end{equation}\\] The pre-exponential factor is \\[\\begin{equation} \\begin{split} \\mathrm{tr}\\, \\mathcal E(X) &amp;= C (-1)^n \\mathrm{Pf}(M)\\mathrm{Pf}(M^{-1}+D)\\mathrm{tr}(X) \\\\ \\mathrm{tr}[\\mathcal E(X)]^2 &amp;= C^2 \\det (I+MD)\\mathrm{tr}(X)^2 \\end{split} \\tag{2.5} \\end{equation}\\] Proof: Picking up from (2.2) \\[\\begin{align} \\mathcal E(X)(\\theta) &amp;= C\\, \\mathrm{tr}(X)\\, \\exp\\left(\\dfrac i 2 \\theta^TA\\theta\\right)\\int D\\eta\\, \\exp \\left[(iB^T \\theta)^T \\eta + \\dfrac i 2 \\eta^T D \\eta \\right] \\int D\\mu\\, \\exp(i \\eta^T \\mu + \\dfrac i 2 \\mu^T M \\mu) X(\\mu) \\\\ &amp;= i^n C \\, \\mathrm{Pf}(M)\\, \\mathrm{tr}(X) \\exp \\left(\\dfrac i 2 \\theta^TA\\theta \\right) \\int D\\eta\\, \\exp \\left[ (iB^T\\theta)^T \\eta + \\dfrac i 2 \\eta^T (D+M^{-1}) \\eta\\right] \\\\ &amp;= i^n C \\, \\mathrm{Pf}(M)\\, \\mathrm{tr}(X) \\exp \\left(\\dfrac i 2 \\theta^TA\\theta \\right) i^n \\mathrm{Pf}(D+M^{-1}) \\exp\\left[\\dfrac i 2 \\theta^T B (D+M^{-1})^{-1} B^T \\theta\\right] \\\\ &amp;= (-1)^n C \\, \\mathrm{Pf}(M)\\, \\mathrm{Pf}(D+M^{-1}) \\, \\mathrm{tr}(X) \\exp\\left[\\dfrac i 2 \\theta^T (B (D+M^{-1})^{-1} B^T + A)\\theta\\right] \\end{align}\\] The \\(\\mathrm{tr}[\\mathcal E(X)]^2\\) formula follows from \\(\\mathrm{Pf}(A)^2=\\det A\\) and \\(\\det A\\, \\det B = \\det(AB)\\). Corollary 2.1 (trace-preserving bistochastic linear maps) If \\(\\mathcal E\\) is trace-preserving (TP), then \\(D=0\\) and \\(C=1\\) in (2.1), in which case \\[ \\mathcal E(M) = BMB^T + A \\] If \\(\\mathcal E\\) is bistochastic (i.e. preserves the identity) then \\(A=D=0\\) and \\[ \\mathcal E(M) = BMB^T \\] Complete-positive Gaussian linear maps It turns out that, when interpreted as a Gaussian channel, the \\(4n\\times 4n\\) block matrix in (2.1) is the covariance matrix of the corresponding Choi state. Theorem 2.5 (fourier characterization of CP Gaussian linear maps) \\(\\mathcal E\\) is completely positive if \\(C\\geq 0\\) and \\[ E = \\begin{pmatrix} A &amp; B \\\\ -B^T &amp; D \\end{pmatrix} \\] satisfies \\(E^TE \\leq I\\). 2.2 Lie algebra embedding Results from (Knill 2001) provide the mathematical link between even and affine Gaussians. Definition 2.3 (Gaussian Lie groups and algebras) Fixing \\(n\\) fermionic modes Let \\(\\mathcal L_1, \\mathcal L_2\\) denote the linear and quadratic polynomials in \\(2n\\) majorana operators, respectively. Let \\(\\mathcal L_2&#39;\\) denote quadratic monomials. Note that \\(\\dim \\mathcal L_2=2n^2 + n + 1, \\dim \\mathcal L_2&#39;=2n^2-n\\). Let \\(\\mathcal L_2^*\\) denote the quadratic polynomials without constant terms, so \\(\\dim \\mathcal L_2^*=2n^2+n\\). Theorem 2.6 (even Gaussian algebra reduction) the affine Gaussian algebra \\(\\mathcal L_2^*\\) is isomorphic to a subalgebra of the even Gaussian algebra \\(\\mathcal L_2&#39;\\) on one more mode. Proof: Let the new mode append majorana operators \\(\\gamma_{2n+1}, \\gamma_{2n+2}\\). Consider \\(\\iota:\\mathcal L_2^*\\to \\mathcal L_2&#39;\\) defined by \\[ \\iota(\\gamma_j) = i \\gamma_j \\gamma_{2n+1}, \\quad \\iota(\\gamma_j\\gamma_k) = \\gamma_j\\gamma_k \\] In short, it appends \\(i\\gamma_{2n+1}\\) to linear terms and leaves quadratic terms unchanged. This is manifestly and injection, to demonstrate embedding it then suffices to show that \\(\\iota\\, [a, b] = [\\iota\\, a, \\iota\\, b]\\). Consider the following representative cases with nonvanishing brackets \\[\\begin{aligned} \\iota\\, [\\gamma_1, \\gamma_2] &amp;= \\iota(2\\gamma_1\\gamma_2) = 2\\gamma_1\\gamma_2 \\\\ [\\iota\\, \\gamma_1, \\iota\\, \\gamma_2] &amp;= [i\\gamma_1\\gamma_{2n+1}, i\\gamma_2\\gamma_{2n+1}] = 2\\gamma_1\\gamma_2 \\\\ \\iota[\\gamma_1, \\gamma_1\\gamma_2] &amp;= \\iota(2\\gamma_2) = 2i\\gamma_2\\gamma_{2n+1} \\\\ [\\iota\\, \\gamma_1, \\iota\\, \\gamma_1\\gamma_2] &amp;= [i\\gamma_1\\gamma_{2n+1}, \\gamma_1\\gamma_2] = 2i\\gamma_2\\gamma_{2n+1} \\end{aligned}\\] Corollary 2.2 (even Gaussian unitary reduction) The affine Gaussian unitary group on \\(n\\) fermionic modes is isomorphic to a subgroup of the even Gaussian unitary group on \\(n+1\\) fermionic modes. 2.3 Affine Gaussian Bibliography Bravyi, Sergey. 2004. “Lagrangian Representation for Fermionic Linear Optics.” arXiv Preprint Quant-Ph/0404180. ———. 2005. “Classical Capacity of Fermionic Product Channels.” arXiv Preprint Quant-Ph/0507282. Knill, Emanuel. 2001. “Fermionic Linear Optics and Matchgates.” arXiv Preprint Quant-Ph/0108033. "],["classical-simulation-results.html", "3 Classical simulation results 3.1 Computational-basis input and measurement 3.2 Bounded output support 3.3 Generalization 3.4 Magic states 3.5 Complexity landscape", " 3 Classical simulation results The pioneering works by (Terhal and DiVincenzo 2002) and (Jozsa and Miyake 2008) provide classical simulation methods for Gaussian circuits under two different conditions, subsequently unified and generalized by (Brod 2016). To the best of our knowledge, (“Computational Power of Matchgates with Supplementary Resources” 2020) provides the comprehensive catalogue of the computational power of fermionic Gaussian circuits under various conditions. 3.1 Computational-basis input and measurement This work (Terhal and DiVincenzo 2002) is the first to draw the connection between Valiant’s matchgates and noninteracting fermions. It is shown that Gaussian circuits with computational basis input and computational-basis von-Neumann measurements are both strongly and adaptively simulable. 3.1.1 Insightful special case Let us first consider a subclass of number-preserving Gaussian unitaries and projective measurements in the computational basis. This case suffices to show the main insight of the paper. Definition 3.1 (number-preserving unitary) A Gaussian unitary \\(U\\) is number-preserving if it does not mix annihilation and creation operators. The following operator \\((V_{jk})\\) is unitary \\[ U a_j^\\dagger U^\\dagger= V_{jk} a_k^\\dagger\\implies U^\\dagger a_j^\\dagger U = V^\\dagger_{jk} a_k^\\dagger, \\quad U^\\dagger a_j U = (V_{jk}^\\dagger)^* a_k = V_{kj} a_k \\] Note that \\(U\\) preserves the hamming weights of computational basis states. In particular, \\(U|0\\rangle= |0\\rangle\\). Proposition 3.1 (computational basis measurement) Let \\(|I\\rangle, |K\\rangle\\) be computational basis states. One can efficiently compute \\(\\langle K|U|I\\rangle\\) by the following procedure. Consider \\[\\begin{aligned} U|I\\rangle &amp;= U a^\\dagger_I |0\\rangle= U a_I^\\dagger U^\\dagger(U|0\\rangle) = \\sum_{j_1\\cdots j_i} V_{I_1j_1}\\cdots V_{I_iJ_i} a_{j_1}^\\dagger\\cdots a_{j_i}^\\dagger|0\\rangle \\end{aligned}\\] When paired with \\(\\langle K|\\), only when \\((j_l)\\) is a permutation of \\(K\\) will this be nonzero, then \\[ \\langle K|U|I\\rangle= \\sum_{J\\in \\pi(K)} \\mathrm{sgn}(J) V_{IJ} = \\det V_{|IK} \\] Here \\(\\pi(K)\\) denotes permutations of \\(K\\) and \\(V_{|IK}\\) is the \\(i\\times i\\) matrix which selects the \\(I\\) rows and \\(K\\) columns of \\(V\\). 3.1.2 Generalization Theorem 3.1 (strong simulation) Given a Gaussian unitary \\(U\\) acting on a computational basis \\(|J\\rangle\\), the probability \\(\\Pr(K^*|J)\\), where \\(K^*\\) of measuring any subset \\(K\\subset [2n]\\) of the qubits and finding the bitstring \\(K^*\\in \\{0, 1\\}^k\\), is efficiently classically computable. The proof extends that of the special case 3.1. One generalizes computational-basis projective to von-Neumann measurement by applying Wick’s theorem and recognizing the sum as a Pfaffian of a cleverly-constructed matrix (instead of the determinant). The generalization from number-preserving to parity-preserving Gaussian unitaries is done by using the majorana instead of the dirac operators. Constructing the matrix whose Pfaffian yield the desired quantity is quite technical. A much more insightful interpretation is that this problem reduces to computing the overlap between \\(U|J\\rangle\\) and the binary Hermitian observable corresponding to \\(K^*\\). Both are Gaussian, so the Gaussian overlap formula 1.4 applies. The next result follows. Theorem 3.2 (adaptive simulation) Adaptive Gaussian circuits with computational-basis input and computational-basis von-Neumann measurements are adaptively simulable. 3.2 Bounded output support The main results of (Jozsa and Miyake 2008) are Decomposition of matchgates into \\(2\\)-qubit unitaries. Strong simulation for Gaussian circuits with arbitrary product-state input and measurement with bounded majorana support. Proof that swap constitutes a resourceful operation. 3.2.1 Matchgate decomposition and simulation Theorem 3.3 (nearest-neighbor (n.n.) matchgate) Gaussian unitaries with support on nearest-neighbor (consecutive two) qubits is of the form \\[ G(A, B) = \\begin{pmatrix} p &amp;&amp;&amp; q \\\\ &amp; w &amp; x &amp; \\\\ &amp; y &amp; z &amp; \\\\ r &amp;&amp;&amp; s \\end{pmatrix}, \\quad A = \\begin{pmatrix} p &amp; q \\\\ r &amp; s\\end{pmatrix}, \\quad B = \\begin{pmatrix} w &amp; x \\\\ y &amp; z \\end{pmatrix} \\] where \\(A, B\\) are both unitary and \\(\\det B = \\det B\\). this amounts to \\(A, B\\) acting on the even and odd subspaces, respectively. Proof: The hermitian quadratic majorana monomials on two qubits are \\[ \\{-i\\gamma_1\\gamma_2, -i\\gamma_2\\gamma_3, i\\gamma_3\\gamma_3, -i\\gamma_2\\gamma_4, i\\gamma_1\\gamma_4, -i\\gamma_3\\gamma_4\\} = \\{ZI, XX, YX, XY, YY, IZ\\} \\] They are all traceless and preserve the even and odd subspaces, so the Lie group they generate must be \\(SU(2)\\oplus SU(2)\\) decomposed relative to the two parity subspaces. Alternatively one may construct the Pauli \\(X, Y, Z\\) operators acting on the two subspaces and apply direct exponentiation. Theorem 3.4 (n.n. decomposition of Gaussian unitaries) Any Gaussian unitary over \\(n\\) qubits is decomposable into \\(O(n^3)\\) n.n. Gaussian unitary. Proof: a Gaussian unitary \\(U\\) affect rotation \\(R\\) of the \\(2n\\) operators. Use Euler-angle decomposition to decompose \\(R\\) into a composition of \\(O(n^2)\\) rotations, each only acting nontrivially on a two-dimensional subspace. Each such rotation can then be implemented by \\(O(n)\\) Gaussian unitaries using the modified swap \\[ S_{12} = \\exp\\left(-\\dfrac\\pi 4 (-\\gamma_1\\gamma_4 + \\gamma_2\\gamma_3 + \\gamma_1\\gamma_2 + \\gamma_3\\gamma_4)\\right) = -iG(Z, X), \\quad S_{12}^\\dagger\\begin{pmatrix} \\gamma_1 \\\\ \\gamma_2\\end{pmatrix}S_{12} = \\begin{pmatrix} \\gamma_3 \\\\ \\gamma_4\\end{pmatrix} \\] Theorem 3.5 (strong simulation) strong simulation of non-adaptive Gaussian circuit with product state input and single-qubit computational-basis output is poly-time. Proof: Let the input be \\(|\\psi\\rangle= \\otimes |\\psi_j\\rangle\\) and the measurement \\(Z_1 = -i\\gamma_1\\gamma_2\\), then \\[ \\langle Z_1\\rangle= (-i) \\langle\\psi|U^\\dagger\\gamma_1\\gamma_2 U|\\psi\\rangle = (-i) \\sum_{j\\neq k} R_{1,j}R_{2,k} \\langle\\psi|\\gamma_j\\gamma_k|\\psi\\rangle \\] By virtue of \\(|\\psi\\rangle\\) being a product state, \\(\\langle\\psi|\\gamma_j\\gamma_k|\\psi\\rangle\\) is poly-computable. 3.2.2 Resourcefulness of swap Theorem 3.6 (universality of ) Any Gaussian unitary over \\(n\\) qubits is decomposable into \\(O(n^3)\\) n.n. Gaussian unitary. 3.3 Generalization Brod shows that Gaussian circuits with arbitrary product states input and arbitrary product-state intermediate measurements remain classically simulable (Brod 2016). 3.3.1 Product input and measurement simulation First note three useful identities: for arbitrary single-qubit state \\(|\\phi\\rangle\\) \\(G(H, H)|\\phi\\rangle|+\\rangle= (H|\\phi\\rangle)|+\\rangle\\) \\(G(Z, X)|\\phi\\rangle|0\\rangle= |0\\rangle|\\phi\\rangle, \\quad G(Z, X)|0\\rangle|\\phi\\rangle= |\\phi\\rangle|0\\rangle\\) \\(G(-Z, X)|\\phi\\rangle|1\\rangle= |1\\rangle|\\phi\\rangle, \\quad G(-Z, X)|1\\rangle|\\phi\\rangle= |\\phi\\rangle|1\\rangle\\) Recall that single-qubit \\(Z\\)-rotations and \\(H\\) generate all single-qubit gates. Therefore one may prepare arbitrary product state, using only Gaussian operations, using the help of a \\(|+\\rangle\\) ancilla as follows: Prepare \\(|0\\rangle|+\\rangle\\mapsto |\\psi_1\\rangle|+\\rangle\\) on the last two qubits. Swap the last of the \\(n\\) qubits to the first register using \\(G(Z, X)\\)s to obtain \\(|\\psi_1\\rangle\\cdots |0\\rangle|+\\rangle\\). Prepare \\(|0\\rangle|+\\rangle\\mapsto |\\psi_2\\rangle|+\\rangle\\) on the last two qubits, and repeat. This yields the following proposition. Proposition 3.2 Let \\(|\\psi\\rangle\\) be a product \\(n\\)-qubit state of single-qubit states, then \\(|\\psi\\rangle|+\\rangle\\) is Gaussian-equivalent to \\(|0\\rangle^{\\otimes n}|+\\rangle\\). Theorem 3.7 (product-input multiple-output strong simulation) Let \\(\\{M_n\\}\\) be a uniform family of (possibly adaptive) quantum circuits with \\(\\mathrm{poly}(n)\\) Gaussian unitaries over \\(n\\) qubits acting on an arbitrary \\(n\\)-qubit product state \\(|\\psi\\rangle= \\otimes |\\psi_n\\rangle\\). The circuit is strongly, as well as adaptively simulable for von-Neumann computational-basis intermediate measurements. Proof: Let the measurement projector be \\(P_{\\tilde y}\\). Note that \\[ |+\\rangle= \\dfrac{1+a_{n+1}^\\dagger} {\\sqrt 2}|0\\rangle \\] The quantity of interest thus becomes \\[\\begin{equation}\\begin{aligned} \\Pr(\\tilde y|\\psi) &amp;= \\dfrac 1 2 \\langle 0_{n+1}|(1+a_{n+1})U^\\dagger M_n^\\dagger P_{\\tilde y}M_n U(1+a_{n+1}^\\dagger)|0_{n+1}\\rangle\\\\ &amp;= \\dfrac 1 2 \\langle 0_{n+1}|a_{n+1}U^\\dagger M_n^\\dagger P_{\\tilde y}M_n Ua_{n+1}^\\dagger|0_{n+1}\\rangle + \\dfrac 1 2 \\langle 0_{n+1}|U^\\dagger M_n^\\dagger P_{\\tilde y}M_n U|0_{n+1}\\rangle\\\\ \\end{aligned}\\tag{3.1}\\end{equation}\\] Of the product \\((1+a_{n+1})\\cdots (1+a_{n+1}^\\dagger)\\), only the terms \\((\\cdots)+a_{n+1}\\cdots a_{n+1}^\\dagger\\) yield nonzero matrix elements; this is by Wick’s theorem, which states that creation and annihilation operators must be pairwise contracted to yield a scalar element (the only normal-ordered operator with nonvanishing vacuum matrix element). One may then recognize \\(\\Pr(\\tilde y|\\psi)\\) as a sum of two Pfaffians via the construction of 3.1. Adaptive simulation follows from projective measurements \\(P_j\\) being parity-preserving. Theorem 3.8 (product-input multiple-output weak simulation) The circuit in 3.7 is weakly simulable for arbitrary product-state von-Neumann measurements. Proof: By use of an ancilla in \\(|+\\rangle\\), we can perform arbitrary single-qubit gate on the last qubit and rotate the measurement basis to a \\(Z\\)-measurement. Doing this measurement collapses the last qubit to \\(|0\\rangle\\) or \\(|1\\rangle\\), upon which we can adaptively f-swap the last and second-last qubits using \\(G(\\pm Z, X)\\) and repeat measurement of the second-last qubit, and so on. This provides weak simulation (sampling scheme) of rbitrary product-state input and measurement on the last \\(k\\) qubits. The proof concludes by the freedom to re-order fermionic modes. 3.3.2 Insightful perspective: affine Gaussian overlap One may see that the single-qubit product state \\(|\\psi\\rangle\\) is affine-Gaussian equivalent to \\(|0\\rangle^{\\otimes n}\\) using a similar protocol. Affine Gaussians include single-qubit unitaries on the first qubit in addition to even Gaussian unitaries. One can prepare \\(|\\psi_n\\rangle\\cdots |\\psi_1\\rangle\\) on the first qubit and f-swap them to their respective positions using \\(G(Z, X)\\); in other words, every single-qubit product state is affine-Gaussian equivalent to \\(|0\\rangle^{\\otimes n}\\). Then \\(\\Pr(\\tilde y|\\psi)\\) as in (3.1) is the tracial overlap between the even-Gaussian Hermitian \\(P_{\\tilde y}\\) and the affine Gaussian \\(U|0\\rangle^{\\otimes n}\\), where \\(U\\) is an affine Gaussian unitary. We can extend the Gaussian overlap formula 1.4 to the case when one of the two operators is not homogeneously even, since they will continue to commute. This constitutes another proof of theorem 3.7. Theorem 3.9 (affine-Gaussian operator overlap) Given Gaussian operators \\(X, Y\\) and \\(Y\\) affine \\[ X(\\eta) = \\exp\\left(\\dfrac i 2 \\eta^T A\\eta\\right), \\quad Y(\\theta) = \\exp\\left(\\dfrac i 2 \\theta^T B\\theta + b^T\\theta\\right) \\] Using theorems 1.3 and 1.1 yields \\[ \\mathrm{tr}(XY) = (-2i)^n \\mathrm{Pf}(A)\\mathrm{Pf}(B - A^{-1}) \\] Proof: \\(X(\\eta)\\) and \\(Y(\\theta)\\) continue to commute, then \\[\\begin{aligned} \\mathrm{tr}(XY) &amp;= (-2)^n \\int D\\theta\\, D\\eta \\, e^{\\theta^T\\eta} X(\\eta) Y(\\theta) \\\\ &amp;= (-2)^n \\int D\\theta \\exp\\left(\\dfrac i 2 \\theta^T B\\theta+b^T\\theta\\right) \\int D\\eta \\, e^{\\theta^T\\eta} \\exp\\left(\\dfrac i 2 \\eta^T A\\eta\\right) \\\\ &amp;= (-2)^n \\int D\\theta \\exp\\left(\\dfrac i 2 \\theta^T B\\theta+b^T\\theta\\right) i^n \\mathrm{Pf}(A) \\exp\\left(-\\dfrac i 2 \\theta^T A^{-1} \\theta\\right) \\\\ &amp;= (-2i)^n\\mathrm{Pf}(A) \\int D\\theta \\exp\\left[\\dfrac i 2 \\theta^T (B-A^{-1})\\theta+b^T\\theta\\right] \\\\ &amp;= (-2i)^n \\mathrm{Pf}(A)\\mathrm{Pf}(B - A^{-1}) \\end{aligned}\\] Recall that affine terms of the Gaussian only affect odd moments so \\(b^T\\theta\\) does not affect the final integral. 3.4 Magic states Josza’s work (Hebenstreit et al. 2019) provides a characterization of resourceful states for Gaussian unitaries. 3.4.1 Measurement-based universal computation Theorem 3.10 (swap gadget construction) weak simulation of Gaussian circuits with magic-state input and adaptive measurements is QC-hard. Proof: It suffices to construct a protocol equivalent to universal quantum computation. 3.4.2 Characterization of magic states 3.5 Complexity landscape The computational power of a circuit model depends on the following ingredients Gate set: here we always consider Gaussian unitaries. Input states (IN): computational basis (CB), general single-qubit product states (PROD), magic states (MAGIC) Intermediate measurements (ADAPT) Final measurement (M): single-qubit (ONE) or multi-qubit product-state (PROD) measurements. The following theorems, together with aforementioned results, completely establish the simulation complexity landscape of Gaussian circuits in terms of adaptiveness, input state (product or magic), output (single-qubit or multiple), and weak or strong simulation. 3.5.1 Non-adaptive single-qubit measurement Theorem 3.11 Strong simulation of non-adaptive Gaussian circuits with magic input and single-qubit measurement is poly-time. 3.5.2 Adaptive single-qubit measurement Theorem 3.12 Strong simulation of adaptive Gaussian circuits with product-state input and single-qubit measurement is #P-hard. 3.5.3 Non-adaptive product-state measurement Theorem 3.13 Strong simulation of nonadaptive Gaussian circuits with magic input and product-state measurement is #P-hard. Theorem 3.14 Weak simulation of nonadaptive Gaussian circuits with magic input and product-state measurement implies polynomial-hierarchy collapse. Bibliography Brod, Daniel J. 2016. “Efficient Classical Simulation of Matchgate Circuits with Generalized Inputs and Measurements.” Physical Review A 93 (6): 062332. “Computational Power of Matchgates with Supplementary Resources.” 2020. Physical Review A 102 (5): 052604. Hebenstreit, Martin, Richard Jozsa, Barbara Kraus, Sergii Strelchuk, and Mithuna Yoganathan. 2019. “All Pure Fermionic Non-Gaussian States Are Magic States for Matchgate Computations.” Physical Review Letters 123 (8): 080503. Jozsa, Richard, and Akimasa Miyake. 2008. “Matchgates and Classical Simulation of Quantum Circuits.” Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences 464 (2100): 3089–3106. Terhal, Barbara M, and David P DiVincenzo. 2002. “Classical Simulation of Noninteracting-Fermion Quantum Circuits.” Physical Review A 65 (3): 032325. "],["bibliography.html", "Bibliography", " Bibliography Bravyi, Sergey. 2004. “Lagrangian Representation for Fermionic Linear Optics.” arXiv Preprint Quant-Ph/0404180. ———. 2005. “Classical Capacity of Fermionic Product Channels.” arXiv Preprint Quant-Ph/0507282. Brod, Daniel J. 2016. “Efficient Classical Simulation of Matchgate Circuits with Generalized Inputs and Measurements.” Physical Review A 93 (6): 062332. “Computational Power of Matchgates with Supplementary Resources.” 2020. Physical Review A 102 (5): 052604. Hebenstreit, Martin, Richard Jozsa, Barbara Kraus, Sergii Strelchuk, and Mithuna Yoganathan. 2019. “All Pure Fermionic Non-Gaussian States Are Magic States for Matchgate Computations.” Physical Review Letters 123 (8): 080503. Hudson, RL, MD Wilkinson, and SN Peck. 1980. “Translation-Invariant Integrals, and Fourier Analysis on Clifford and Grassmann Algebras.” Journal of Functional Analysis 37 (1): 68–87. Jozsa, Richard, and Akimasa Miyake. 2008. “Matchgates and Classical Simulation of Quantum Circuits.” Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences 464 (2100): 3089–3106. Knill, Emanuel. 2001. “Fermionic Linear Optics and Matchgates.” arXiv Preprint Quant-Ph/0108033. Terhal, Barbara M, and David P DiVincenzo. 2002. “Classical Simulation of Noninteracting-Fermion Quantum Circuits.” Physical Review A 65 (3): 032325. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
